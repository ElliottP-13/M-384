\documentclass[11pt]{article}
\usepackage{../EllioStyle}

\title{Homework 1}
\author{Elliott Pryor}
\date{24 Jan 2021}

\rhead{Homework 1}

\begin{document}
\maketitle

\problem{1} 6.1.5 Problem 3

Derive the integration of the derivative theorem from the differentiation of 
the integral theorem. Can you prove the converse implication?

You \textbf{don't} need to prove the converse case. Here, assume the differentiation of the integral
theorem is true, namely,

$$\frac{d}{dx} \int_a ^x g(t) dt = g(x)$$ 

for any continuous function $g(x)$ on $[a,b]$ and $a \leq x \leq b$, you need to use this to prove:

$$\int_a ^b f'(x) dx = f(b) - f(a)$$

for any $C^1$ function $f$ on $[a,b]$.

\textbf{Hint:} Consider function

$$G(x) = \int_a ^x f'(t)dt, \sp a \leq x \leq b$$
and see how $G(x)$ and $f(x)$ are related.
\hrule


\begin{proof}
    We want to show 

    $$\int_a ^b f'(x) dx = f(b) - f(a)$$

    From theorem 6.1.2, we know that:

    $$F(x) = \int_a ^x f(t)dt, \quad F'(x) = f(x)$$.

    We consider the function: $G(x) = \int_a ^x f'(t)dt$. 
    Then from theorem 6.1.2, we know that $G'(x) = f'(x)$, so $G(x) = f(x) + c$ where $c \in \reals$

    We evaluate $G(b) - G(a)$ using this information.

    $$G(b) - G(a) = (f(b) + c) - (f(a) + c) = f(b) - f(a)$$

    We also know from the definition of $G(x)$ that:

    $$G(b) - G(a) = \int_a ^b f'(t)dt - \int_a ^a f'(t)dt = \int_a ^b f'(t)dt $$
    
    since $\int_i ^j h(x)dx \leq (j - a) \sup_{x \in [i,j]}(h(x))$, so $\int_a ^a f'(t)dt = 0$.

    Then we know that $\int_a ^b f'(t)dt = G(b) - G(a) = f(b) - f(a)$

\end{proof}



\problem{2} 6.1.5 Problem 4

Prove the integral mean value theorem: if $f$ is continuous on $[a,b]$ then there exists $y$ in $(a,b)$ 
such that $\int_a ^b f(x) dx = (b - a)f(y)$
\hrule


\begin{proof}
    Given a function $f$ is continuous on $[a,b]$, we need to find a $y$ such that $\int_a ^b f(x) dx = (b-a) f(y)$. 
    Consider $M = \sup_{x \in [a,b]}f(x)$ and $m = \inf_{x \in [a,b]}f(x)$. Then clearly $m \leq f(x) \leq M \sp \forall x \in [a,b]$. 
    So consider $\int_a ^b f(x)dx \leq \int_a ^b Mdx = M \int_a ^b dx = M(b - a)$, and $\int_a ^b f(x)dx \geq \int_a ^b mdx = m \int_a ^b dx = m(b - a)$.
    Thus we have $m (b - a) \leq \int_a ^b f(x) dx \leq M (b - a)$.

    We know that $\int_a ^b f(x) dx = (b - a) K$ for some $K$. So then, from above we have $m (b - a) \leq K (b-a) \leq M (b - a) \rightarrow m \leq K \leq M$.
    So we are looking for $f(y) = K$. Since $f$ is a continuous function, by the Inermediate Value Theorem (theorem 4.2.2), there exists some $y \in [a,b]$ such that $f(y) = K$.

\end{proof}





\problem{3} 6.1.5 Problem 8

Let $f$ be a $C^1$ function on the line, and let $g(x) = \int_0 ^1 f(xy)y^2 dy$.
Prove that $g$ is a $C^1$ function and establish a formula for $g'(x)$ in terms of $f$

\textbf{Hint:} Use theorem 6.1.7
\hrule

\begin{proof}
    First we say that $h(x,y) = f(xy)y^2$. Then we can use Theorem 6.1.7. $$g(x) = \int_{a(x)} ^{b(x)} h(x,y) dy$$
    and $$g'(x) = h(x, b(x))b'(x) - h(x, a(x))a'(x) + \int_{a(x)} ^{b(x)} \frac{\partial h}{\partial x}(x,y)dy$$

    In this case: $a(x) = 0, \sp a'(x) = 0$ and $b(x) = 1, \sp b'(x) = 0$. 
    We then evaluate $\frac{\partial h}{\partial x}(x,y) = y f'(xy)y^2 = f'(xy) y^3$
    We plug this into our expression of $g'$ resulting in 

    $$g'(x) = \int_0 ^1 y^3 \cdot f'(xy) dy$$

    Since $f$ is a $C^1$ function on the line, $f'(xy)$ exists and is continous everywhere. 
    Thus the derivative of $g$, exists and is continuous everywhere. Therefore $g \in C^1$
\end{proof}



\problem{4} 6.1.5 Problem 10

For a continuous, positive function $w(x)$ on $[a,b]$, define the weighted average operator $A_w$ to be:

$$A_w(f) = \frac{ \int_a ^b f(x) w(x) dx }{ \int_a ^b w(x) dx}$$

for continuous functions $f$. Prove that $A_w$ is linear and lies between the maximum and mininum values of $f$.

\textbf{Hint:} $A_w$ is linear if
$$A_w (c_1 f + c_2 g) = c_1 A_w (f) + c_2 A_w (g)$$
for any constants $c_1, c_2$ and continuous functions $f,g$ on $[a,b]$
\hrule

We will prove this in two parts: 
\begin{proof}
    We start by showing that $A_w$ is linear. 
    So we need to show that $A_w(c_1 f + c_2 g) = c_1 A_w(f) + c_2 A_w(g)$

    \begin{align*}
        A_w(c_1 f + c_2 g) &= \frac{ \int_a ^b (c_1 f(x) + c_2 g(x)) w(x) dx }{ \int_a ^b w(x) dx}\\
        &= \frac{ \int_a ^b c_1 f(x) w(x) + c_2 g(x) w(x) dx }{ \int_a ^b w(x) dx} \\
        &= \frac{ \int_a ^b c_1 f(x) w(x) dx + \int_a ^b c_2 g(x) w(x) dx }{ \int_a ^b w(x) dx} \\
        &= \frac{ \int_a ^b c_1 f(x) w(x) dx}{ \int_a ^b w(x) dx} + \frac{\int_a ^b c_2 g(x) w(x) dx }{ \int_a ^b w(x) dx} \\
        &= c_1 \frac{ \int_a ^b f(x) w(x) dx}{ \int_a ^b w(x) dx} + c_2 \frac{\int_a ^b g(x) w(x) dx }{ \int_a ^b w(x) dx} \\
        &= c_1 A_w(f(x)) + c_2 A_w(g(x)) \\
    \end{align*}
\end{proof}

\begin{proof}
    We next show that $A_w$ must be between the minimum and maximum values of $f$. 
    Let $m = \inf_{x \in [a,b]} f(x)$, and $M = \sup_{x \in [a,b]} f(x)$. Then:

    \begin{align*}
        \frac{ \int_a ^b m w(x) dx }{ \int_a ^b w(x) dx} &\leq \frac{ \int_a ^b f(x) w(x) dx }{ \int_a ^b w(x) dx} \leq \frac{ \int_a ^b M w(x) dx }{ \int_a ^b w(x) dx}\\
        m &\leq \frac{ \int_a ^b f(x) w(x) dx }{ \int_a ^b w(x) dx} \leq M\\
        m &\leq A_w(f) \leq M
    \end{align*}
    $$$$




\end{proof}


\end{document}