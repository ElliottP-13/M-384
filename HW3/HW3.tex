\documentclass[11pt]{article}
\usepackage{../EllioStyle}

\title{Homework 3}
\author{Elliott Pryor}
\date{14 Feb 2021}

\rhead{Homework 3}

\begin{document}
\maketitle

\problem{1} 6.3.1 Problem 1

For which values of $a$ and $b$ does the improper integral

$$\int_0 ^{1/2} x^a | \log x|^b dx$$
exist


\textbf{Hint:} Consider $a > -1$, $a < -1$, $a = -1$ separately.

If $a > -1$ then $\exists \epsilon > 0$ such that $a - \epsilon > -1$ or $\epsilon = \frac{a +1}{2}$. 
Thus we have $$\int_0 ^{1/2} x^a | \log x|^b dx = \int_0 ^{1/2} x^{a - \epsilon} x^\epsilon | \log x|^b dx$$
Since $\epsilon > 0$, fo any $b$, by L'Hopital's rule (you don't need to prove this), we have $\lim_{x \to 0^+} x^\epsilon |\log x|^b = 0$

So the convergence of the integral is determined by $x^{a - \epsilon}$

If $a < -1$, we use similar argument writing $x^a = x^{a + \epsilon} x ^{- \epsilon}$, and use L'Hopital's rule to show
$\lim_{x \to 0^+} x^{-\epsilon}| \log x |^b = \infty$

If $a = -1$ use substitutions $u = \log x$ to convert it to a form that the results are known.

\hrule



\begin{proof}
    We examine three different cases: $a > -1, a = -1, a < -1$

    Case 1, $a > -1$. Then $\exists \epsilon > 0$ such that $a - \epsilon > -1$. 
    Thus we have $$\int_0 ^{1/2} x^a | \log x|^b dx = \int_0 ^{1/2} x^{a - \epsilon} x^\epsilon | \log x|^b dx$$
    Since $\epsilon > 0$, for any $b$, by L'Hopital's rule, we have $\lim_{x \to 0^+} x^\epsilon |\log x|^b = 0$
    
    Then the convergence of the integral is dependent on $x^a$. We showed in class that $\int_0 ^1 x^a$ converges for $-1 < a < 0$.
    Thus the limit exists, and the improper integral $\int_0 ^{1/2} x^a | \log x|^b dx$ is defined for $-1 < a < 0, \sp \forall b$


    Case 2, $a = -1$. Then $\int_0 ^{1/2} x^a | \log x|^b dx = \int_0 ^{1/2} x^-1 | \log x|^b dx$. Let $u = \log x$ and $du = 1/x dx$.
    Then we have $\int_{\log 0} ^{\log 1/2} |u|^b du = \Eval{u ^{b+1}}{-\infty}{\log 1/2}$. This exists if $b < -1$.
    We know this since this function is similar to $x^c$, which has an integrable singularity at $\infty$ iff $c < -1$.
    So, the improper integral $\int_0 ^{1/2} x^a | \log x|^b dx$ is defined for $a = -1, b < -1$

    Case 3, $a < -1$. Then $\exists \epsilon > 0$ such that $a + \epsilon < -1$.  Thus we have
    $$\int_0 ^{1/2} x^a | \log x|^b dx = \int_0 ^{1/2} x^{a + \epsilon} x^{-\epsilon} | \log x|^b dx$$
    Then, from L'Hopitals rule we know that: $\lim_{x \to 0^+} x^{-\epsilon} |\log x|^b = \infty$
    Therefore, regardless of choice of $a$. The integral diverges.

    Thus we have the improper integral $\int_0 ^{1/2} x^a | \log x|^b dx$ is defined for $-1 < a < 0, \sp \forall b$, and $a = -1, b < -1$

\end{proof}



\problem{2} 7.2.4 Problem 1

Give an example of two convergent series $\sum_{k = 1} ^\infty x_k$ and $\sum_{k = 1} ^\infty y_k$
such that $\sum_{k = 1} ^\infty x_k y_k$ diverges. Can this happen if one of the series is absolutely convergent?

\textbf{Hint:} For the first part, consider the alternating series. 
For the second part, if one series is absolutely convergent, consider to use the Cauchy Criterion and the fact
that every term in the other series is bounded.

\hrule

For the first part, let $x_k = (-1)^k (k)^{-1/2}$ $y_k = (-1)^{k+1} (k)^{-1/2}$.
So $x_k = -1 + 1/\sqrt{2} - 1/\sqrt{3} + ...$ and $y_k = 1 - 1/\sqrt{2} + 1/\sqrt{3} - ...$.
Or in other words, $y_k = (-1) x_k$. Clearly both are convergent sequences by alternating series test,
where $A_n = n^{-1/2}$ which is monotonically decreasing. But $x_k \cdot y_k = (-1) k^{-1}$. So
$\sum_{k = 1} ^\infty x_k \cdot y_k = (-1) \sum_{k = 1} ^\infty k^{-1}$ which is divergent.


For the second part, we use the Cauchy criterion to show that $\sum_{k = 1} ^\infty x_k \cdot y_k$ is convergent.
Without loss of generality, assume that $x_k$ is absolutely convergent. We know that since $\sum_{k = 1} ^\infty y_k$ is convergent $y_k$ is bounded,
then $\exists N > 0$ st $|y_k| \leq N$ $\forall k$. Then we show the cauchy criterion: $\forall 1/n \sp \exists m \sp st \sp \forall q \geq p \geq m \sp \left| \sum_{k = p} ^q x_k \cdot y_k \right| < 1/n$: 
$$ \left| \sum_{k = p} ^q x_k \cdot y_k \right| \leq  \sum_{k = p} ^q \left| x_k \cdot y_k \right| \leq \sum_{k = p} ^q \left| x_k \cdot N \right| = N \sum_{k = p} ^q \left| x_k \right|$$
which is convergent since $|x_k|$ is convergent.






\problem{3} 7.2.4 Problem 2

State a contrapositive form of the comparison test that can be used to show divergence of a series

\textbf{Hint} You can assume the terms of both series are non-negative, and you don't need to prove the statement.


\hrule

We assume that the terms of both series are non-negative. 

Let $\sum_{k=1} ^\infty x_k$ and $\sum_{k=1} ^\infty y_k$ be infinite series. And $x_k \geq y_k$ for all but finite number of terms.
Then if $\sum_{k=1} ^\infty y_k$ is divergent, then $\sum_{k=1} ^\infty x_k$ is also divergent.





\problem{4} 7.2.4 Problem 4

Prove the ratio test (Theorem 7.2.3a). What does this tell you if $lim_{n \to \infty} |x_{n+1} / n|$ exists?

\textbf{Hint: } Use comparison test with geometric series, and then use the Cauchy criterion.

\hrule





\end{document}